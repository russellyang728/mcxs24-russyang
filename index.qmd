---
title: "The Effects of Fiscal Policy Shifts on Unemployment Rates"
author: "Yansong Yang"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** This study investigates the dynamic impact of fiscal policy shifts on unemployment rates through a Structural Vector Autoregression (SVAR) model. Utilizing time series data for government spending, tax revenue, inflation, and unemployment rates, we analyze the interplay between fiscal activities and labor market performance within an Australian context. The SVAR model, equipped to dissect the influence of systematic fiscal shocks, reveals insights into how fiscal policy affects employment.
>
> **Keywords.** SVARs, Fiscal Policy, Unemployment Rates, Government Spending, Tax Revenue, Sign Restriction

# 1. The Question, Objective, and Motivation

The objective of this research project is to assess the effects of fiscal policy shifts on unemployment rates. I aim to investigate how unemployment rates respond to changes in government spending and taxation under various fiscal policy frameworks.

Unemployment is pivotal in the macroeconomic framework, directly tied to social welfare and economic performance. Considering the economic challenges faced by Australia, the examination of fiscal policy's influence on unemployment is timely. For instance, @leigh2012 found that fiscal consolidation efforts in Australia could potentially lift unemployment rates in the short term. @Chapman2000AvoidingRA identified that the Australian labor market exhibits notable sensitivity to macroeconomic policy shifts, with fiscal measures playing a significant role in shaping employment trends. These findings have piqued my curiosity about understanding fiscal policy mechanisms in the Australian labor market. By conducting this research, I aim to provide an updated empirical analysis of how contemporary fiscal policy adjustments are impacting unemployment rates in Australia, thereby offering insights that may inform policy refinement for enhanced economic resilience and labor stability.

# 2. Data and Their Properties

## 2.1 Variables Selected

Unemployment Rate(UNEMP)(in %): Monthly data on the unemployment rate in Australia, sourced from the Australian Bureau of Statistics (ABS). In further steps, it will be converted to quarterly data.

Government Spending(GOVSPEND)(in Million$): Quarterly data on total government expenditure, including both consumption and investment, also obtained from ABS.

Tax Revenue(TAXREV)(in Million$): Quarterly tax revenue data for the Australian government, which can be sourced from ABS.

Inflation Rate(INFL)(in %): The consumer price index (CPI) from which the quarterly inflation rate can be calculated, available from ABS.

Real Gross Domestic Product(RGDP)(in Million$): Quarterly data of the value of all goods and services produced by Australia, adjusted for inflation. Sourced from RBA.

Cash Rate Target(CR)(in%): Quarterly data of the interest rate that banks pay to borrow funds from central banks in the overnight markets, set by RBA.

## 2.2 Why Chose Them?

The chosen variables are integral to capturing the broad dynamics of fiscal policy and its impact on the labor market. The unemployment rate (UNEMP) is the direct indicator of labor market health. Government spending (GOVSPEND) and tax revenue (TAXREV) are key fiscal policy tools that directly affect aggregate demand, and by extension, employment and output. Inflation rate (INFL) is a crucial economic indicator that can reflect the demand-pull effects in the economy which, in a Keynesian context, may affect the level of employment. Real GDP(RGDP) is included as it reflects the overall economic output and health, directly correlating with job market strength. The cash rate(CR) is a measure of monetary policy influence on fiscal effectiveness and employment levels.

## 2.3 Data Visualization

```{r include=FALSE}
library(readabs)
library(readrba)
library(xts)
library(ggplot2)
library(patchwork)
library(tseries)
library(knitr)
library(zoo)
library(dplyr)

#download data
cr_dwld <- readrba::read_rba(series_id = "FIRMMCRTD")
cr <- cr_dwld[, c("date", "value")]
cr <- xts::xts(cr$value,cr$date)
cr <- xts::to.quarterly(cr, OHLC = FALSE)
start_date <- start(cr)
end_date1 <- as.Date("2023-12-31")
end_date2 <- as.yearqtr("2023 Q4")

cr = window(cr, start=start_date, end=end_date2)

cr_p = autoplot(cr) +
  theme_classic()+
  labs(title = "Cash Rate Target")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

#unemployment rate data
unemp_dwnld <- readabs::read_abs(series_id = 'A84423050A') 
unemp <- xts(unemp_dwnld$value, order.by=as.Date(unemp_dwnld$date))

# Covert monthly unemployment data to quarterly for analysis compatibility. 
unemp <- to.quarterly(unemp,OHLC = FALSE)
unemp <- window(unemp, start=start_date, end=end_date2)

unemp_p = autoplot(unemp) +
  theme_classic()+
  scale_x_yearqtr(format = "%Y")+
  labs(title = "Unemployment Rate")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

#government spending data
govspend_dwnld <- readabs::read_abs(series_id = 'A2304080V')
govspend <- xts(govspend_dwnld$value, order.by=as.Date(govspend_dwnld$date))
govspend <- window(govspend, start=start_date, end=end_date1)

govspend_p = autoplot(govspend) +
  theme_classic()+
  labs(title = "Government Spending")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

#tax revenue data
taxrev_dwnld <- readabs::read_abs(series_id = 'A2302794K')
taxrev <- xts(taxrev_dwnld$value, order.by=as.Date(taxrev_dwnld$date))
taxrev <- window(taxrev, start=start_date, end=end_date1)
taxrev_p = autoplot(taxrev) +
  theme_classic()+
  labs(title = "Tax Revenue")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

#inflation data
infl_dwnld <- readabs::read_abs(series_id = 'A2325850V')
infl <- xts(infl_dwnld$value, order.by=as.Date(infl_dwnld$date))
infl <- window(infl, start=start_date, end=end_date1)
infl_p = autoplot(infl) +
  theme_classic()+
  labs(title = "Inflation")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

# real gdp data
rgdp_dwld <- readrba::read_rba(series_id = "GGDPCVGDP")
rgdp <- rgdp_dwld[, c("date", "value")]
rgdp$quarter <- zoo::as.yearqtr(rgdp$date)
rgdp <- xts::xts(rgdp$value,rgdp$quarter)
rgdp <- window(rgdp, start=start_date, end=end_date2)
rgdp_p = autoplot(rgdp) +
  theme_classic()+
  labs(title = "Real GDP")+
  theme(axis.title.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"))

```

The time series plots\[Figure 1: Time Series Data\] for unemployment rate, government spending, tax revenue, and inflation collectively offer a glimpse into the interplay between fiscal policy and economic indicators in an economy. The unemployment rate displays cyclical patterns with notable spikes, hinting at its sensitivity to economic conditions and potentially reactive fiscal policies. The upward trajectories of both government spending and tax revenue suggest an expanding fiscal capacity over time, likely driven by both economic growth and policy decisions.

Government spending's steady rise, with occasional steeper inclines, could imply proactive fiscal stimulus during periods of economic downturn, which often sees a lagged corresponding dip in the unemployment rate. Tax revenue's increase, while generally consistent with economic growth, also shows sensitivity to business cycles, indicating that it's both a reflection of and a contributor to the fiscal environment. Inflation's volatility is without a clear trend line.

The steady increase of Real GDP shows the economy’s growth and resilience in response to policy measures and global economic shifts. The fluctuations in the Cash Rate Target reflect the central bank’s monetary policy adjustments aimed at maintaining stability and stimulating economic activity.

These time series hint at a complex relationship where fiscal policy, through government spending and tax revenue, aims to moderate the impacts of economic cycles on unemployment, all while operating within the broader context influenced by inflation dynamics. The ebb and flow in these indicators reflect the challenges and responses in managing an economy over time.

```{r fig.show='hold', out.width='100%'}
#| echo: false
#| message: false
#| warning: false
#| layout-nrow: 3
#| fig-cap: "Time Series Data"

combined_plot <- unemp_p + govspend_p + taxrev_p + infl_p + rgdp_p + cr_p +
  plot_layout(nrow = 3, ncol = 2) + 
  plot_annotation(
    title = "Time Series Data"
  )

combined_plot

```

\[Table 1: Summary Statistic\] shows variables' description during 1990 Q1 to 2023 Q4.

```{r}
#| echo: false
#| message: false

data_df <- data.frame(
  unemp = coredata(unemp),
  govspend = coredata(govspend),
  taxrev = coredata(taxrev),
  infl = coredata(infl),
  rgdp = coredata(rgdp),
  cr = coredata(cr)
)

Variable = c('unemp', 'govspend', 'taxrev','infl', 'rgdp','cr')
Length <- rep(136, length(Variable))
Mean <- sapply(data_df, mean)
SD <- sapply(data_df, sd)
Min <- sapply(data_df, min)
Max <- sapply(data_df, max)
table1 =data.frame(Length, Mean,SD, Min, Max)

knitr::kable(table1, caption = "Summary Statistics", digits = 2)
```

## 2.4 Property Tested

From the ACF test\[Figure 2: Autocorrelation Function\], the unemployment rate shows a strong initial correlation that quickly tails off, indicating that past unemployment only affects the current rate for a short period. Government spending and tax revenue, on the other hand, display more prolonged correlations, suggesting that current values are influenced by a longer history of the series. This persistence might be a sign of a trend or other non-stationary behavior in the series. Inflation shows some initial correlation that diminishes, which could be indicative of cyclical behavior being smoothed out over time.

From the PACF test\[Figure 3: Partial Autocorrelation Function\], for unemployment, there's a significant direct correlation with the immediate past, which is not seen in the following lags. This indicates that other than the most recent past, there's little direct effect on the current unemployment rate. In the case of government spending, tax revenue, and inflation, the PACF plots suggest that after accounting for other factors, the direct correlations are quite minimal. This could imply that these time series are driven by a more complex set of factors than just their immediate past values.

```{r fig.show='hold', out.width='80%'}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Autocorrelation Function"

par(mfrow = c(2, 3))
acf(unemp,  plot = TRUE, main = "Unemplyment Rate")
acf(govspend, plot = TRUE , main = "Government Spending")
acf(taxrev, plot = TRUE , main = "Tax Revenue")
acf(infl, plot = TRUE , main = "Inflation")
acf(rgdp, plot = TRUE , main = "Real GDP")
acf(cr, plot = TRUE , main = "Cash Rate Target")

```

```{r fig.show='hold', out.width='80%'}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Partial Autocorrelation Function"
 
par(mfrow = c(2, 3))
pacf(unemp,  plot = TRUE, main = "Unemplyment Rate")
pacf(govspend, plot = TRUE , main = "Government Spending")
pacf(taxrev, plot = TRUE , main = "Tax Revenue")
pacf(infl, plot = TRUE , main = "Inflation")
pacf(rgdp, plot = TRUE , main = "Real GDP")
pacf(cr, plot = TRUE , main = "Cash Rate Target")

```

# 3. Methodology

## 3.1 Basic Model

The **Structural Form (SF) model** of Structural VARs is:

$$
\begin{gather*}
B_{0} Y_{t} =b_{0}  + \sum_{i=1}^{p} (B_{i}Y_{t-i} )+u_{t} \\
u_{t}|Y_{t-1} \sim iid(0_{N},I_{N}  )
\end{gather*}
$$

-   $Y_{t}$ is $N \times 1$ matrix of endogenous variable.

-   $B_{0}$ is $N \times N$ matrix of contemporaneous relationships also called structural matrix. It captures contemporaneous relationships between variables.

-   $u_{t}$ is a $N \times 1$ vector of conditionally on$Y_{t-1}$orthogonal or independent structural shocks. Isolating these shocks allows us to identify dynamic effects of uncorrelated shocks on variables $Y_{t}$.

$$
Y_t= 
\begin{pmatrix}
unemp_t\\
 govspend_t\\
 taxrev_t\\
 infl_t\\
 gdp_t\\
 cr_t
\end{pmatrix}
$$ 

The **Reduced Form (RF)** representation is:

$$
\begin{gather*}
Y_{t} =\mu_{0}  + \sum_{i=1}^{p} (A_{i}Y_{t-i} )+\epsilon_{t} \\
\epsilon_{t}|Y_{t-1} \sim iid(0_{N},\Sigma )
\end{gather*}
$$

Either of the SF models lead to the same RF representation through various equivalence transformations

$$
\begin{gather*}
\epsilon_t = B u_t = B_0^{-1} u_t \\
B_0 \epsilon_t = u_t \\
\Sigma = BB' = B_0^{-1} B_0'^{-1}
\end{gather*}
$$

Rewrite the RF models in matrix

$$
\begin{gather*}
\mathbf{Y} = \mathbf{X}\mathbf{A} + \mathbf{E} \\
\mathbf{E}|\mathbf{X} \sim MN_{T \times N}(0_{T \times N},\Sigma,I_T) 
\end{gather*} 
$$

The first step is to sample the reduced-form parameters ($A$, $\Sigma$). Adopting the conjugate Normal-Inverse-Wishart prior,

$$
\begin{align*}
\mathbf{A}| \mathbf{\Sigma} &\sim \mathcal{MN}_{K \times N}(\underline{\mathbf{A}},\mathbf{\Sigma}, \underline{\mathbf{V}}) \\
\Sigma &\sim \mathcal{IW}_N(\underline{\mathbf{S}}, \underline{\nu})
\end{align*}
$$

From Minnesota Prior, we have following parameters

$$
\begin{align}
\underline{A} &= [0_{N \times 1} \quad I_N \quad 0_{N \times (p-1)N}]' \\ 
Var[vec(A)] &= \Sigma \otimes  \underline{V} \\
\underline{V} &= \text{diag}([\kappa_2 \quad \kappa_1 (p^{-2} \otimes \imath_N)]) \\
\end{align}
$$
$\kappa_1$ is the overall shrinkage level for autoregressive slopes with common value $0.02^{2}$. But in this report, I take value $1^{2}$.

$\kappa_2$ is the overall shrinkage level for the constant term with common value $100$.

$p$ is the length. And, finally let

$$
\begin{align*}
\hat{A} &= (X'X)^{-1}X'Y \\
R &= (Y - X\hat{A})'(Y - X\hat{A})
\end{align*}
$$

For the full conditional posterior distribution, we have

$$
\begin{align*}
p(A, \Sigma | Y) &\propto |\Sigma|^{-T/2} \exp \left\{ -\frac{1}{2} \text{tr}\left[(Y - XA)'(Y - XA)\right] \right\} \\
&\quad \times |\Sigma|^{-T/2} \exp \left\{ -\frac{1}{2} \text{tr}\left[(A - \underline{A})'\underline{V}^{-1}(A - \underline{A})\right] \right\} \\
&\quad \times |\Sigma|^{-(\underline{\nu}+N+1)/2} \exp \left\{ -\frac{1}{2} \text{tr}(\underline{S}\Sigma^{-1}) \right\} \\
&\propto |\Sigma|^{-T/2} \exp \left\{ -\frac{1}{2} \text{tr}\left[ ((A - \hat{A})'X'X(A - \hat{A}) + (A - \underline{A})'\underline{V}^{-1}(A - \underline{A}))\Sigma^{-1}\right] \right\} \\
&\quad \times |\Sigma|^{-(\underline{\nu}+T+N+1)/2} \exp \left\{ -\frac{1}{2} \text{tr}\left[ (R + \underline{S})\Sigma^{-1}\right] \right\} \\
&= |\Sigma|^{-T/2} \exp \left\{ -\frac{1}{2} \text{tr}\left[ (A - \bar{A})'\bar{V}^{-1}(A - \bar{A})\Sigma^{-1}\right] \right\} \\
&\quad\times |\Sigma|^{-(\underline{\nu}+T+N+1)/2}\exp\left\{ -\frac{1}{2}\text{tr}\left[ (R+\underline{S}+\hat{A}'X'X\hat{A}+\underline{A}'\underline{V}^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A})\Sigma^{-1} \right] \right\} \\
&=|\Sigma|^{-T/2}\exp\left\{ -\frac{1}{2} \text{tr}\left[ (A-\overline{A})'\overline{V}^{-1}(A-\overline{A}) \Sigma^{-1} \right] \right\} \\
&\quad\times |\Sigma|^{-(\underline{\nu}+T+N+1)/2}\exp\left\{ -\frac{1}{2}\text{tr}\left[ (Y'Y+\underline{S}+\underline{A}'\underline{V}^{-1}\underline{A}-\overline{A}'\overline{V}\overline{A})\Sigma^{-1} \right] \right\} \\
&=p(A|\Sigma,Y)\times p(\Sigma|Y)
\end{align*}
$$
Then we get

$$
\begin{align*}
A|\Sigma,Y &\sim \mathcal{MN}_{K\times N}(\overline{A}, \Sigma, \overline{V},) \\
\Sigma|Y &\sim \mathcal{IW}_N(\overline{S}, \overline{\nu})
\end{align*}
$$
where

$$
\begin{align*}
\overline{V} &= (X'X+\underline{V}^{-1})^{-1} \\
\overline{A} &= \overline{V}(X'Y+\underline{V}^{-1}\underline{A}) \\
\overline{\nu} &= \underline{\nu}+T \\
\overline{S} &= \underline{S}+Y'Y+\underline{A}'\underline{V}^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A}
\end{align*}
$$

Here are model process:

1. We can draw $\Sigma^{(s)}$ and then $A^{(s)}$ for each iteration $s$ to form sample draws through joint posterior distribution $\left\{ {A^{(s)}, \Sigma^{(s)}} \right\}^{S}_{s=1}$.

2. Then, compute the initial value of SF parameters to have $\tilde{B_{0}} = chol(\Sigma^{(s)-1})$ and $\tilde{B_{+}} = \tilde{B_{0}} A^{(s)}$.

3. From here, we employ sign restriction by adopting a diagonal restrict matrix $R$. Let $P$ be an $N*N$ random matrix with each element having an independent standard normal distribution. Let $P$ = $QR$ be the $QR$ decomposition of $P$ with the diagonal of R normalized to be positive. The random matrix Q is orthogonal and is a draw from the Haar distribution which is a uniform distribution over orthogonal matrices $O(N)$.

4. Use matrix $Q^{(D)}$ to compute parameters $B_{0} = Q\tilde{B_{0}}$ and $B_{+} = Q\tilde{B_{+}}$.

5. From above, get corresponding IRF(Impulse Response Function) to check whether conducted parameters satisfy sign restriction or not. If not, back to Step 3 to draw new parameters.


## 3.2 Simulation of Basic Model

First, we test the dynamics of two bi-variate Gaussian random walk processes,which are explored below. The graphs display these walks over 1,000 time observations.

```{r fig.show='hold', out.width='60%'}
#| echo: false
#| label: fig-actificial-data
#| fig-cap: Bi-variate Gaussian random walk

set.seed(2048)
RW1 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)
plot.ts(RW1,main="Random Walk 1", col=4,xlab="")

RW2 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)
plot.ts(RW2,main="Random Walk 2", col=4,xlab="")

RW  <- cbind(RW1,RW2)
```

```{r}
#| echo: false
#| message: false
#| warning: false

Y = RW[2:nrow(RW),]
X = matrix(1,nrow(Y),1)
X = cbind(X,RW[2: nrow(RW)-1,])
N = 2
p = 1
K = 1+p*N
S = 1000
 
A.hat = solve(t(X)%*%X)%*%t(X)%*%Y                
Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)
 
kappa.1 = 1
kappa.2 = 100
A.prior = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:3,] = diag(N)
V.prior = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior = diag(diag(Sigma.hat))
nu.prior = N+1
```

```{r}
#| echo: true
#| message: false
#| warning: false
V.bar.inv = t(X)%*%X + diag(1/diag(V.prior))
V.bar = solve(V.bar.inv)
A.bar = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
nu.bar = nrow(Y) + nu.prior
S.bar = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
S.bar.inv = solve(S.bar)

Sigma.posterior = rWishart(S, df=nu.bar, Sigma=S.bar.inv) 
Sigma.posterior = apply(Sigma.posterior,3,solve)
Sigma.posterior = array(Sigma.posterior,c(N,N,S))
A.posterior = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) # whole random draw of A
B0.tilde = array(NA,c(N,N,S))
L = t(chol(V.bar))
Bplus.tilde = array(NA,c(N,K,S))
 
 for (s in 1:S){
   cholSigma.s = chol(Sigma.posterior[,,s])
   B0.tilde[,,s] = solve(t(cholSigma.s)) 
   A.posterior[,,s] = A.bar + L%*%A.posterior[,,s]%*%cholSigma.s # for each random draw of A
   Bplus.tilde[,,s] = B0.tilde[,,s]%*%t(A.posterior[,,s]) 
 } 
 restriction = diag(c(1,1))
 i.vec = c()
 Q.store = array(NA,c(N,N,S))
 B0.store = array(NA,c(N,N,S))
 Bplus.store = array(NA,c(N,K,S))
 A.store = array (NA,c(K,N,S))
 Sigma.store = array(NA,c(N,N,S))

 for (s in 1:S) {
   A = A.posterior[,,s]
   Sigma = Sigma.posterior[,,s]
   B0.tilde1 = B0.tilde[,,s]
   Bplus.tilde1 = Bplus.tilde[,,s]
   
   sign.restrictions.do.not.hold = TRUE
   i=1
   
   while (sign.restrictions.do.not.hold){
     X = matrix(rnorm(N*N),N,N)
     QR = qr(X, tol = 1e-10)
     Q = qr.Q(QR,complete=TRUE)
     R = qr.R(QR,complete=TRUE)
     Q = t(Q %*% diag(sign(diag(R))))
     B0 = Q%*%B0.tilde1
     Bplus = Q%*%Bplus.tilde1
     B0.inv = solve(B0)
     check = all(diag(B0)>0)
     if (check==1){sign.restrictions.do.not.hold=FALSE}
     i=i+1
   }
   i.vec <- c(i.vec, i)
   Q.store[,,s] <- Q
   B0.store[,,s] <- B0
   B0.mean <- apply(B0.store,1:2,mean)
   Bplus.store[,,s] <- Bplus
   Bplus.mean <- apply(Bplus.store,1:2,mean)
 }
 
```

Then after drawing, we have following results of $A$ and $\Sigma$.

```{r Tables showing A and Sigma from the random walks}
#| echo: false
#| message: false
#| warning: false

A_mean <- apply(A.posterior, 1:2, mean)
A_df <- as.data.frame(A_mean)
colnames(A_df) <- c("Simulation_Y1", "Simulation_Y2")
rownames(A_df) <- c("Constant", "Y1-Lag", "Y2-Lag")
knitr::kable(A_df, caption = "Posterior Mean of A")

```

```{r}
#| echo: false
#| message: false
#| warning: false

Sigma_mean <- apply(Sigma.posterior, 1:2, mean)
Sigma_df <- as.data.frame(Sigma_mean)
colnames(Sigma_df) <- c("Simulation_Y1", "Simulation_Y2")
rownames(Sigma_df) <- c("Y1-Lag", "Y2-Lag")

knitr::kable(Sigma_df, caption = "Posterior Mean of Sigma")

```

From the tables of posterior mean of $B_0$ and $B+$.The signs of the coefficients in both $B_0$ and $B+$ matrices are consistent across corresponding variables. This suggests that the model structure may correctly capture the dynamic relationships between variables. Also,  the strong influence of Y1-Lag on Simulation_Y1(0.64) and Y2-Lag on Simulation_Y2 (0.65) suggests similar dynamic responses in these directions.

```{r}
#| echo: false
#| message: false
#| warning: false

B0_df <- as.data.frame(B0.mean)
colnames(B0_df) <- c("Y1-Lag", "Y2-Lag")
rownames(B0_df) <- c("Simulation_Y1", "Simulation_Y2")

knitr::kable(B0_df, caption = "Posterior Mean of B0")
```

```{r}
#| echo: false
#| message: false
#| warning: false

Bplus_df <- as.data.frame(Bplus.mean)
colnames(Bplus_df) <- c("Constant","Y1-Lag", "Y2-Lag")
rownames(Bplus_df) <- c("Simulation_Y1", "Simulation_Y2")

knitr::kable(Bplus_df, caption = "Posterior Mean of B+") 
```

## 3.3 Extension Model

Since from released public reports, the mean of $A$ is seldom deeply analyzed.  Hence, we try to discover an extension on $A$.


$\underline{a}$ is the prior mean only for diagonal elements of $A_1$. So, 


$$
\begin{align*}
&\underline{a}*\underline{A}=[O_{N*1}\ \ \ \underline{a}_N \mathbf{I}_N\ \ \ O_{N*(p-1)N}]'\\
\\
\mathbf{A}| \mathbf{\Sigma},\underline{a} &\sim \mathcal{MN}(\underline{a}\underline{\mathbf{A}},\mathbf{\Sigma}, \underline{\mathbf{V}})  \\
\\
 &\underline{a} \sim N(\underline{m}_a,\underline{s}^2_a) \\
\end{align*}
$$

The full conditional posterior of $\underline{a}$ can be derived as below:

$$
\begin{align*}
&\underline{a}|Y,X,A,\Sigma \propto L(A,\Sigma,Y,X)p(A|\Sigma,\underline{a}) p(\Sigma) p(\underline{a}) \\
& \propto p(\underline{a})\left[\prod_{n=1}^Np(A_{1,nn}|\Sigma,\underline{a},\underline{V})\right] \\
\end{align*}
$$
where

$$
\begin{align*}
A_{1,nn}|\Sigma,\underline{a},\underline{V} &\sim N(\underline{a},\Sigma_{nn}\underline{V}_{(n+1)(n+1)})
\end{align*}
$$

So we have

$$
\begin{align*}
&\propto p(\underline{a})\left[\prod_{n=1}^Np(A_{1,nn}|\Sigma,\underline{a},\underline{V})\right] \\
& \propto exp\left\{ -\frac{1}{2}\frac{(\underline{a}-m_a)^2}{\underline{s}^2_a} \right\}
exp\left\{ -\frac{(\underline{a}-A_{1,11})^2}{\Sigma_{11}\underline{V}_{22}} \right\}
exp\left\{ -\frac{(\underline{a}-A_{1,22})^2}{\Sigma_{22}\underline{V}_{33}} \right\} ···
exp\left\{ -\frac{(\underline{a}-A_{1,nn})^2}{\Sigma_{nn}\underline{V}_{(n+1)(n+1)}} \right\}\\
& = exp\left\{ -\frac{1}{2}\left(\frac{(\underline{a}-m_a)^2}{\underline{s}^2_a}+ \frac{(\underline{a}-A_{1,11}
)^2}{\Sigma_{11}\underline{V}_{22}} + \frac{(\underline{a}-A_{1,22}
)^2}{\Sigma_{22}\underline{V}_{33}}+···+\frac{(\underline{a}-A_{1,nn})^2}{\Sigma_{nn}\underline{V}_{(n+1)(n+1)}}\right)  \right\} \\
& = exp\left\{-\frac{1}{2} \left(\underline{a}^2(\frac{1}{\underline{s}^2_a}+ \frac{1}{\Sigma_{11}\underline{V}_{22}} + \frac{1}{\Sigma_{22}\underline{V}_{33}}+···+\frac{1}{\Sigma_{nn}\underline{V}_{(n+1)(n+1)}}) -2a(\frac{m_a}{\underline{s}^2_a}+ \frac{A_{1,11}}{\Sigma_{11}\underline{V}_{22}} + \frac{A_{1,22}}{\Sigma_{22}\underline{V}_{33}}···+\frac{A_{1,nn}}{\Sigma_{nn}\underline{V}_{(n+1)(n+1)}})+Constant\right) \right\}\\
& = exp \left\{-\frac{1}{2}(\frac{(\underline{a}-\overline{a})^2}{\overline{s}^2_a}) \right\} 
\end{align*}
$$

Hence, full conditional posterior of $\underline{a}$ is in a form of normal distribution where,

$$
\begin{align*}
\overline{s}^2_a = (\frac{1}{\underline{s}^2_a}+\frac{1}{\Sigma_{11}V_{22}}+···+\frac{1}{\Sigma_{nn}V_{(n+1)(n+1)}})^{-1} \\
\overline{a} = \overline{s_a}^2(\frac{m_a}{\underline{s}^2_a}+\frac{A_{1,11}}{\Sigma_{11}V_{22}}+···+\frac{A_{1,nn}}{\Sigma_{nn}V_{(n+1)(n+1)}})
\end{align*}
$$


## 3.4 Simulation of Extension Model

Different to $Section3.2$, Gibb Sampler is used to get draws. 

At each iteration, 

1. Compute $\overline{a}$ and $\overline{s}^2_a$.

2. Draw sample $\overline{a}^{(s)}|\Sigma^{(s-1)},A^{(s-1)}$.

3. Compute $\overline{A},\overline{V},\overline{S},\overline{\nu}$.

4. Draw sample $\Sigma^{(s)},A^{(s)}|\overline{a}^{(s)}$.

```{r fig.show='hold', out.width='60%'}
#| echo: false

set.seed(2048)
RW11 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)
RW22 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)

RW.1 <- cbind(RW11,RW22)
```

```{r}
#| echo: false
#| message: false
#| warning: false

Y <- RW.1[2:nrow(RW.1),]

Y            = RW.1[2:nrow(RW.1),]
X            = matrix(1,nrow(Y),1)
X            = cbind(X,RW.1[2: nrow(RW.1)-1,])
N            = 2            # number of variables
p            = 1            # number of lags
K            = 1+p*N
S            = 5000         # sample size

sign.restrictions = c(1,1)

A.hat = solve(t(X)%*%X)%*%t(X)%*%Y                
Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

kappa.1     <- 1
kappa.2     <- 100

A.prior     <- matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N+1),] <- diag(N)
V.prior     <- diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior     <- diag(diag(Sigma.hat))
nu.prior    <- N+1
m_a =1
```

```{r}
#| echo: true
#| message: false
#| warning: false

Sigma.posterior.store    <- array(NA, c(N,N,S))
A.posterior.store        <- array(NA, c((1+p*N),N,S))
B0.posterior.store       <- array(NA,c(N,N,S))
B1.posterior.store       <- array(NA,c(N,K,S))

compute_sbar2 = function(s2, Sigma, V) {
  sbar2 = 1/s2
  for (i in 1:nrow(Sigma)) {
    sbar2 = sbar2 + 1/(Sigma[i,i]*V[i+1,i+1])
  }
  return(1/sbar2)
}

compute_a_posterior = function(sbar2, Sigma,V,A){
  a_posterior = m_a/sbar2
  n=nrow(Sigma)
  A_1 = A[2:(n+1),]
  for(i in 1:n) {
    a_posterior = a_posterior + A_1[i,i]/(Sigma[i,i]*V[i+1,i+1])
  }
  return(sbar2*a_posterior)
}

s2 = 0.1
a.posterior.store = numeric(S)
Sigma.posterior   <- rWishart(1, df=nu.prior, Sigma=S.prior)[,,1]
V.bar = V.prior
A.posterior = A.prior

for (s in 1:S){
  sbar2 = compute_sbar2(s2, Sigma.posterior,V.bar)
  a_posterior = compute_a_posterior(sbar2, Sigma.posterior,V.bar, A.posterior)
  a.posterior = rnorm(1, a_posterior, sqrt(sbar2))
  a.posterior.store[s] = a.posterior
    
  # Matrix normal-inverse Wishart posterior parameters
  V.bar.inv <- t(X)%*%X + diag(1/diag(V.prior))
  V.bar     <- solve(V.bar.inv)
  A.bar     <- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%(A.prior*a.posterior))
  nu.bar    <- nrow(Y) + nu.prior
  S.bar     <- S.prior + t(Y)%*%Y + t((A.prior*a.posterior))%*%diag(1/diag(V.prior))%*%(A.prior*a.posterior) - t(A.bar)%*%V.bar.inv%*%A.bar
  S.bar.inv <- solve(S.bar)
  
  
  # Draw Posterior distribution
  Sigma.posterior   <- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]
  Sigma.posterior.store[,,s]   <- solve(Sigma.posterior)
  
  # Draw A from matrix-variate normal distribution
  A.posterior = matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior.store[,,s]%x%V.bar), ncol=N)
  A.posterior.store[,,s] = A.posterior
  
  ## Draw from the Structural Form
  cholSigma.s        <- chol(Sigma.posterior.store[,,s])
  B0.posterior.store[,,s]  <- solve(t(cholSigma.s)) 
  B1.posterior.store[,,s]  <- B0.posterior.store[,,s]%*%t(A.posterior.store [,,s])
}

# Identification via sign restrictions 
R1 <- diag(sign.restrictions)

# Storage matrices for Q identified estimates
i.vec <- c()
Q.store      <- array(NA,c(N,N,(S)))
B0.store    <- array(NA,c(N,N,(S)))
B1.store     <- array(NA,c(N,K,(S)))
A.store     <- array(NA,c(K,N,S))
Sigma.store  <- array(NA,c(N,N,S))

for (s in 1:S){
  A             <- A.posterior.store[,,s]
  Sigma         <- Sigma.posterior.store[,,s]
  B0.tilde      <- B0.posterior.store[,,s]
  B1.tilde      <- B1.posterior.store[,,s]
  
  sign.restrictions.do.not.hold = TRUE
  i=1
  while (sign.restrictions.do.not.hold){
    X           <- matrix(rnorm(N*N),N,N)         
    QR          <- qr(X, tol = 1e-10)
    Q           <- qr.Q(QR,complete=TRUE)
    R           <- qr.R(QR,complete=TRUE)
    Q           <- t(Q %*% diag(sign(diag(R))))
    B0          <- Q%*%B0.tilde                    
    B1          <- Q%*%B1.tilde                   
    B0.inv      <- solve(B0)      
    check       <- all(c(B0[1,1], B0[2,2]) > 0)
    
    if (check){sign.restrictions.do.not.hold=FALSE}
    i=i+1 
  }
  i.vec <- c(i.vec,i) 
  
  Q.store[,,s] <- Q
  B0.store[,,s] <- B0
  B0.mean <- apply(B0.store,1:2,mean)
  B1.store[,,s] <- B1
  B1.mean <- apply(B1.store,1:2,mean)
  A.store[,,s]       <- A
  A.mean             <- apply(A,1:2,mean)
  Sigma.store[,,s]   <- Sigma
  Sigma.mean         <- apply(Sigma,1:2,mean)
}

```

We get the mean of $\overline{a}$ first:

```{r}
#| echo: false
#| message: false
#| warning: false

a_mean <- data.frame(a = mean(a.posterior.store))
colnames(a_mean) <- "Posterior Mean of a"
knitr::kable(a_mean,align = 'c',index = FALSE)

```

And then generate the results of posterior mean of $A$ and $\Sigma$. Both covariance close to identity matrix.

```{r}
#| echo: false
#| message: false
#| warning: false

A_mean <- apply(A.posterior, 1:2, mean)
A_df <- as.data.frame(A_mean)
colnames(A_df) <- c("Simulation_Y1ext", "Simulation_Y2ext")
rownames(A_df) <- c("Constant", "Y1-Lag", "Y2-Lag")
knitr::kable(A_df, caption = "Posterior Mean of A")

```

```{r}
#| echo: false
#| message: false
#| warning: false

Sigma_mean <- apply(Sigma.posterior, 1:2, mean)
Sigma_df <- as.data.frame(Sigma_mean)
colnames(Sigma_df) <- c("Simulation_Y1ext", "Simulation_Y2ext")
rownames(Sigma_df) <- c("Y1-Lag", "Y2-Lag")

knitr::kable(Sigma_df, caption = "Posterior Mean of Sigma")

```

The sign restrictions seem to enforce non-negative impacts in the matrix elements.  Because all parameters in $B_0$ and $B+$ are with positive sign. 

```{r}
#| echo: false
#| message: false
#| warning: false

B0_df <- as.data.frame(B0.mean)
colnames(B0_df) <- c("Y1-Lag", "Y2-Lag")
rownames(B0_df) <- c("Simulation_Y1ext", "Simulation_Y2ext")

knitr::kable(B0_df, caption = "Posterior Mean of B0")
```

```{r}
#| echo: false
#| message: false
#| warning: false

Bplus_df <- as.data.frame(Bplus.mean)
colnames(Bplus_df) <- c("Constant","Y1-Lag", "Y2-Lag")
rownames(Bplus_df) <- c("Simulation_Y1ext", "Simulation_Y2ext")

knitr::kable(Bplus_df, caption = "Posterior Mean of B+") 
```


# 4. Empirical Analysis

## 4.1 Impulse Response

Impulse response functions(IRF) to orthogonal shocks computed for an empirically relevant SVAR model are considered the dynamic causal effects of the underlying shocks on economic measurements, $Y_t$ for example.

The following graphs are impulse responses of basic model after real data are incorporated. The response of unemployment rate is slightly decreasing, indicating that the shock might have a limited but negative impact on it. The slight upward trend  suggests an expansion in government expenditure following the shock. Obvious positive effect is shown by tax revenue,real GDP, and cash rate target while initial jump followed by stabilization of inflation suggests that the shock might lead to short-term inflationary pressures that stabilize over time.

From the impulse response plots, we can conclude there is significant effect on government spending, but insignificant for others.

```{r}
#| echo: false
#| message: false
#| warning: false

### Incorporate real data
Y = data_df[2:nrow(data_df),]
Y <- as.matrix(Y)
X = matrix(1,nrow(Y),1)
X = cbind(X,data_df[2: nrow(data_df)-1,])
X <- as.matrix(X)
N = 6
p = 1
K = 1+p*N
S = Length[1]

# MLE
###############
A.hat = solve(t(X)%*%X)%*%t(X)%*%Y                
Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# prior distribution
###############
kappa.1 = 1
kappa.2 = 100
A.prior = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N+1),] = diag(N)
V.prior = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior = diag(diag(Sigma.hat))
nu.prior = N+1

# normal-inverse Wishard posterior parameters
###############
V.bar.inv = t(X)%*%X + diag(1/diag(V.prior))
V.bar = solve(V.bar.inv)
A.bar = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
nu.bar = nrow(Y) + nu.prior
S.bar = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
S.bar.inv = solve(S.bar)

# posterior draws 
###############
Sigma.posterior = rWishart(S, df=nu.bar, Sigma=S.bar.inv) 
Sigma.posterior = apply(Sigma.posterior,3,solve)
Sigma.posterior = array(Sigma.posterior,c(N,N,S))
A.posterior = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) # whole random draw of A
B0.tilde = array(NA,c(N,N,S))
L = t(chol(V.bar))
Bplus.tilde = array(NA,c(N,K,S))

for (s in 1:S){
  cholSigma.s = chol(Sigma.posterior[,,s])
  B0.tilde[,,s] = solve(t(cholSigma.s)) 
  A.posterior[,,s] = A.bar + L%*%A.posterior[,,s]%*%cholSigma.s # for each random draw of A
  Bplus.tilde[,,s] = B0.tilde[,,s]%*%t(A.posterior[,,s]) 
} 
restriction = diag(c(0,1,-1,-1,0,0))
i.vec = c()
Q.store = array(NA,c(N,N,S))
B0.store = array(NA,c(N,N,S))
Bplus.store = array(NA,c(N,K,S))
A.store = array (NA,c(K,N,S))
Sigma.store = array(NA,c(N,N,S))

for (s in 1:S) {
  A = A.posterior[,,s]
  Sigma = Sigma.posterior[,,s]
  B0.tilde1 = B0.tilde[,,s]
  Bplus.tilde1 = Bplus.tilde[,,s]
  
  sign.restrictions.do.not.hold = TRUE
  i=1
  
  while (sign.restrictions.do.not.hold){
    Z = matrix(rnorm(N*N),N,N)
    QR = qr(Z, tol = 1e-10)
    Q = qr.Q(QR,complete=TRUE)
    R = qr.R(QR,complete=TRUE)
    Q = t(Q %*% diag(sign(diag(R))))
    B0 = Q%*%B0.tilde1
    Bplus = Q%*%Bplus.tilde1
    B0.inv = solve(B0)
    check = all(B0.inv[2,2] > 0, B0.inv[3,2]<0, B0.inv[4,2]<0 )
    if (check){sign.restrictions.do.not.hold=FALSE}
    i=i+1
  }
  i.vec <- c(i.vec, i)
  Q.store[,,s] <- Q
  B0.store[,,s] <- B0
  B0.mean <- apply(B0.store,1:2,mean)
  Bplus.store[,,s] <- Bplus
  Bplus.mean <- apply(Bplus.store,1:2,mean)
  A.store[,,s]       <- A
  A.mean             <- apply(A,1:2,mean)
  Sigma.store[,,s]   <- Sigma
  Sigma.mean         <- apply(Sigma,1:2,mean)
}

```

```{r}
#| echo: false
#| message: false
#| warning: false

######## IRF ########
#A.posterior = array(NA,c(K,N,S))
B.posterior = array(NA,c(N,N,S))

for (s in 1:S){
  B = solve(B0.store[,,s])
  B.posterior[,,s]= B 
  #A.posterior[,,s]= t(B %*% B1.store[,,s]) 
}

h=8
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))
for (s in 1:S){
  A.bold          = rbind(t(A.store[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior

IRF.posterior.mps = IRF.posterior[,2,,]
IRFs.k1           = apply(IRF.posterior.mps,1:2,median)
IRFs.k1           = apply(IRF.posterior.mps,1:2,median)
IRFs.inf.k1       = apply(IRF.posterior.mps,1,mean)
rownames(IRFs.k1) = colnames(data_df)

library(HDInterval)
IRFs.k1.hdi    = apply(IRF.posterior.mps,1:2,hdi, credMass=0.68)
hh             = 1:(h+1)

names <- c("Unemployment Rate","Government Spending","Tax Revenue","Inflation","Real GDP","Cash Rate Target")

par(mfrow=c(4,2), mar=c(2,2,2,2),cex.axis=1, cex.lab=1)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,1:(h+1)],0)
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", main=names[n])
  if (n==5){
    axis(1,c(1,5,9),c("0","1 year","2 year"))
  } else {
    axis(1,c(1,5,9),c("0","1 year","2 year"))
  }
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col="#8EE4AF",border="#756BB1")
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col="black")
}

```

Here are the impulse responses for extension model. Compared with baseline model, even the effect on government spending turns to insignificant.

```{r}
#| echo: false
#| message: false
#| warning: false

#########Extension model#########

Y = data_df[2:nrow(data_df),]
Y <- as.matrix(Y)
X = matrix(1,nrow(Y),1)
X = cbind(X,data_df[2: nrow(data_df)-1,])
X <- as.matrix(X)
N = 6            # number of variables
p = 1            # number of lags
K = 1+p*N
S  = Length[1]         # sample size


A.hat = solve(t(X)%*%X)%*%t(X)%*%Y                
Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

kappa.1     <- 1
kappa.2     <- 100

A.prior     <- matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N+1),] <- diag(N)
V.prior     <- diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior     <- diag(diag(Sigma.hat))
nu.prior    <- N+1
m_a =1

Sigma.posterior.store    <- array(NA, c(N,N,S))
A.posterior.store        <- array(NA, c((1+p*N),N,S))
B0.posterior.store       <- array(NA,c(N,N,S))
B1.posterior.store       <- array(NA,c(N,K,S))

compute_sbar2 = function(s2, Sigma, V) {
  sbar2 = 1/s2
  for (i in 1:nrow(Sigma)) {
    sbar2 = sbar2 + 1/(Sigma[i,i]*V[i+1,i+1])
  }
  return(1/sbar2)
}

compute_a_posterior = function(sbar2, Sigma,V,A){
  a_posterior = m_a/sbar2
  n=nrow(Sigma)
  A_1 = A[2:nrow(A),]
  for(i in 1:n) {
    a_posterior = a_posterior + A_1[i,i]/(Sigma[i,i]*V[i+1,i+1])
  }
  return(sbar2*a_posterior)
}

s2 = 0.1
a.posterior.store = numeric(S)
Sigma.posterior   <- rWishart(1, df=nu.prior, Sigma=S.prior)[,,1]
V.bar = V.prior
A.posterior = A.prior

for (s in 1:S){
  sbar2 = compute_sbar2(s2, Sigma.posterior,V.bar)
  a_posterior = compute_a_posterior(sbar2, Sigma.posterior,V.bar, A.posterior)
  a.posterior = rnorm(1, a_posterior, sqrt(sbar2))
  a.posterior.store[s] = a.posterior
  
  # Matrix normal-inverse Wishart posterior parameters
  V.bar.inv <- t(X)%*%X + diag(1/diag(V.prior))
  V.bar     <- solve(V.bar.inv)
  A.bar     <- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%(A.prior*a.posterior))
  nu.bar    <- nrow(Y) + nu.prior
  S.bar     <- S.prior + t(Y)%*%Y + t((A.prior*a.posterior))%*%diag(1/diag(V.prior))%*%(A.prior*a.posterior) - t(A.bar)%*%V.bar.inv%*%A.bar
  S.bar.inv <- solve(S.bar)
  
  
  # Draw Posterior distribution
  Sigma.posterior   <- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]
  Sigma.posterior.store[,,s]   <- solve(Sigma.posterior)
  
  # Draw A from matrix-variate normal distribution
  A.posterior = matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior.store[,,s]%x%V.bar), ncol=N)
  A.posterior.store[,,s] = A.posterior
  
  ## Draw from the Structural Form
  cholSigma.s        <- chol(Sigma.posterior.store[,,s])
  B0.posterior.store[,,s]  <- solve(t(cholSigma.s)) 
  B1.posterior.store[,,s]  <- B0.posterior.store[,,s]%*%t(A.posterior.store [,,s])
}

# Identification via sign restrictions 
R1 <- diag(c(0,1,-1,-1,0,0))

# Storage matrices for Q identified estimates
i.vec <- c()
Q.store      <- array(NA,c(N,N,(S)))
B0.store    <- array(NA,c(N,N,(S)))
B1.store     <- array(NA,c(N,K,(S)))
A.store     <- array(NA,c(K,N,S))
Sigma.store  <- array(NA,c(N,N,S))

for (s in 1:S){
  A             <- A.posterior.store[,,s]
  Sigma         <- Sigma.posterior.store[,,s]
  B0.tilde      <- B0.posterior.store[,,s]
  B1.tilde      <- B1.posterior.store[,,s]
  
  sign.restrictions.do.not.hold = TRUE
  i=1
  while (sign.restrictions.do.not.hold){
    Z           <- matrix(rnorm(N*N),N,N)         
    QR          <- qr(Z, tol = 1e-10)
    Q           <- qr.Q(QR,complete=TRUE)
    R           <- qr.R(QR,complete=TRUE)
    Q           <- t(Q %*% diag(sign(diag(R))))
    B0          <- Q%*%B0.tilde                    
    B1          <- Q%*%B1.tilde                   
    B0.inv      <- solve(B0)      
    check       <- all(B0.inv[2,2] > 0, B0.inv[3,2]<0, B0.inv[4,2]<0 )
    
    if (check){sign.restrictions.do.not.hold=FALSE}
    i=i+1 
  }
  i.vec <- c(i.vec,i) 
  
  Q.store[,,s] <- Q
  B0.store[,,s] <- B0
  B0.mean <- apply(B0.store,1:2,mean)
  B1.store[,,s] <- B1
  B1.mean <- apply(B1.store,1:2,mean)
  A.store[,,s]       <- A
  A.mean             <- apply(A,1:2,mean)
  Sigma.store[,,s]   <- Sigma
  Sigma.mean         <- apply(Sigma,1:2,mean)
}

```

```{r}
#| echo: false
#| message: false
#| warning: false

#A.posterior = array(NA,c(K,N,S))
B.posterior = array(NA,c(N,N,S))

for (s in 1:S){
  B = solve(B0.store[,,s])
  B.posterior[,,s]= B 
  #A.posterior[,,s]= t(B %*% B1.store[,,s]) 
}

h=8
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))
for (s in 1:S){
  A.bold          = rbind(t(A.store[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior

IRF.posterior.mps = IRF.posterior[,2,,]
IRFs.k1           = apply(IRF.posterior.mps,1:2,median)
IRFs.k1           = apply(IRF.posterior.mps,1:2,median)
IRFs.inf.k1       = apply(IRF.posterior.mps,1,mean)
rownames(IRFs.k1) = colnames(data_df)

library(HDInterval)
IRFs.k1.hdi    = apply(IRF.posterior.mps,1:2,hdi, credMass=0.68)
hh             = 1:(h+1)

names <- c("Unemployment Rate","Government Spending","Tax Revenue","Inflation","Real GDP", "Cash Rate Target")

par(mfrow=c(4,2), mar=c(2,2,2,2),cex.axis=1, cex.lab=1)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,1:(h+1)],0)
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", main=names[n])
  if (n==5){
    axis(1,c(1,5,9),c("0","1 year","2 year"))
  } else {
    axis(1,c(1,5,9),c("0","1 year","2 year"))
  }
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col="#EDF5E1",border="#756BB1")
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col="black")
}

```


## References {.unnumbered}
